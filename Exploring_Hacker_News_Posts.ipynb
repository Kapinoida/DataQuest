{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "We are eploring [Hacker News](https://news.ycombinator.com/) posts, specifically, the comparison of two different types of posts, `Ask HN` and `Show HN` posts.\n",
    "\n",
    "For `Ask HN` posts, users will submit a question to the Hacker News community (ie. \"What is that best programming language to learn for data science?\"). In `Show HN` posts, users post project, products, and other interesting technology related items.\n",
    "\n",
    "We will campare these two types of posts to learn the following:\n",
    "- Do `Ask HN` or `Show HN` recieve more comments on average?\n",
    "- Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "We are working with a reduced dataset, shrunk from 300,000 to 20,000 rows. This was done by removing posts with no comments and randomly sampling the rest to hit the smaller size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "from csv import reader\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of the date we are working with. Just 7 columns worth of categories, most important being the title, number of comments and dates.\n",
    "\n",
    "Before we get too far, let's remove the header from the dataset, but keep it for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Separating Ask HN and Show HN posts\n",
    "\n",
    "A key step in the process is finding the `Ask HN` and `Show HN` posts and creating our own datasets to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1744\n",
      "1162\n",
      "17194\n"
     ]
    }
   ],
   "source": [
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Average Number of Comments\n",
    "\n",
    "Now that we separated the data, let's look at the average number of comments for both types of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.038417431192661\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "    \n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print(avg_ask_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.31669535283993\n"
     ]
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print(avg_show_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, ask posts get around 14 comments while show posts get around 10. Ask posts are more likely to get more attention, so we will focus more on that as we proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask Posts and Comments by Hour\n",
    "\n",
    "Now lets look at the time that will most likely attract comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': 447,\n",
       " '01': 683,\n",
       " '02': 1381,\n",
       " '03': 421,\n",
       " '04': 337,\n",
       " '05': 464,\n",
       " '06': 397,\n",
       " '07': 267,\n",
       " '08': 492,\n",
       " '09': 251,\n",
       " '10': 793,\n",
       " '11': 641,\n",
       " '12': 687,\n",
       " '13': 1253,\n",
       " '14': 1416,\n",
       " '15': 4477,\n",
       " '16': 1814,\n",
       " '17': 1146,\n",
       " '18': 1439,\n",
       " '19': 1188,\n",
       " '20': 1722,\n",
       " '21': 1745,\n",
       " '22': 479,\n",
       " '23': 543}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6], int(row[4])])\n",
    "    \n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date = row[0]\n",
    "    comments = row[1]\n",
    "    hour = dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\").strftime(\"%H\")\n",
    "    \n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = comments\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += comments\n",
    "        \n",
    "comments_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Average per Hour\n",
    "\n",
    "We can see some of the data above with the amount of comments categorized by hour. Hour 15 (3pm EST) seems to be by far the largest amount of comments in the hour. However, let's compare the amount of comments to the amount of posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['00', 8.13],\n",
       " ['20', 21.52],\n",
       " ['18', 13.2],\n",
       " ['07', 7.85],\n",
       " ['14', 13.23],\n",
       " ['04', 7.17],\n",
       " ['19', 10.8],\n",
       " ['12', 9.41],\n",
       " ['17', 11.46],\n",
       " ['09', 5.58],\n",
       " ['16', 16.8],\n",
       " ['03', 7.8],\n",
       " ['02', 23.81],\n",
       " ['13', 14.74],\n",
       " ['23', 7.99],\n",
       " ['10', 13.44],\n",
       " ['01', 11.38],\n",
       " ['22', 6.75],\n",
       " ['08', 10.25],\n",
       " ['21', 16.01],\n",
       " ['05', 10.09],\n",
       " ['06', 9.02],\n",
       " ['15', 38.59],\n",
       " ['11', 11.05]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_by_hour =[]\n",
    "\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, round((comments_by_hour[hour] / counts_by_hour[hour]), 2)])\n",
    "    \n",
    "avg_by_hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.13, '00'], [21.52, '20'], [13.2, '18'], [7.85, '07'], [13.23, '14'], [7.17, '04'], [10.8, '19'], [9.41, '12'], [11.46, '17'], [5.58, '09'], [16.8, '16'], [7.8, '03'], [23.81, '02'], [14.74, '13'], [7.99, '23'], [13.44, '10'], [11.38, '01'], [6.75, '22'], [10.25, '08'], [16.01, '21'], [10.09, '05'], [9.02, '06'], [38.59, '15'], [11.05, '11']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[38.59, '15'],\n",
       " [23.81, '02'],\n",
       " [21.52, '20'],\n",
       " [16.8, '16'],\n",
       " [16.01, '21'],\n",
       " [14.74, '13'],\n",
       " [13.44, '10'],\n",
       " [13.23, '14'],\n",
       " [13.2, '18'],\n",
       " [11.46, '17'],\n",
       " [11.38, '01'],\n",
       " [11.05, '11'],\n",
       " [10.8, '19'],\n",
       " [10.25, '08'],\n",
       " [10.09, '05'],\n",
       " [9.41, '12'],\n",
       " [9.02, '06'],\n",
       " [8.13, '00'],\n",
       " [7.99, '23'],\n",
       " [7.85, '07'],\n",
       " [7.8, '03'],\n",
       " [7.17, '04'],\n",
       " [6.75, '22'],\n",
       " [5.58, '09']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "sorted_swap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Post Comment\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Post Comment\")\n",
    "\n",
    "for avg, hour in sorted_swap[:5]:\n",
    "    print(\n",
    "        \"{}: {:.2f} average comments per post\".format(dt.datetime.strptime(hour, \"%H\")\n",
    "                                                      .strftime(\"%H:%M\"),avg)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "As we can see, the top hour is hour 15 (3pm EST). We can use this to maximize the amount of comments that are aquired when making a post on Hacker Noon in the `Ask HN` catergory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ending notes for continued expansion\n",
    "\n",
    "That's it for the guided steps! Here's a quick summary of what we accomplished in this guided project:\n",
    "\n",
    "- We set a goal for the project.\n",
    "- We collected and sorted the data.\n",
    "- We reformatted and cleaned the data to prepare it for analysis.\n",
    "- We analyzed the data.\n",
    "\n",
    "Guided projects can be used to build a portfolio to showcase to potential employers, so we encourage you to keep working on this. Here are some next steps for you to consider:\n",
    "\n",
    "- Determine if show or ask posts receive more points on average.\n",
    "- Determine if posts created at a certain time are more likely to receive more points.\n",
    "- Compare your results to the average number of comments and points other posts receive.\n",
    "- Use Dataquest's [data science project style guide](https://www.dataquest.io/blog/data-science-project-style-guide/) to format your project.\n",
    "\n",
    "You're welcome to keep working on the project here, but we recommend downloading it to your computer using the download icon above the notebook and working on it locally.\n",
    "\n",
    "If you choose to work on the next steps independently, you'll inevitably not know how to perform certain tasks or hit errors that you won't know how to resolve. Don't get discouraged! This is part of the learning process. Although referring back to previous missions is a great way to refresh your memory on certain topics, there are also a couple tools you should get familiar with because you'll need to use them in a real world job setting.\n",
    "\n",
    "The best thing to do if you hit an error you can't resolve or don't know how to perform a task is search for the answer on Google. When you search, make sure to include the word \"python\" — otherwise, you'll get results from other programming languages. For example, instead of searching for \"how to find the first element in a list,\" search for \"python how to find the first element in a list.\"\n",
    "\n",
    "As you search, you'll see one site constantly appear at the top of the results — Stack Overflow. Stack Overflow is an online community where people ask and answer programming questions. In most situations, you'll find that someone has asked the same question as you or a similar question that can help you. The community is very active, so the answers are almost always accurate.\n",
    "\n",
    "Congratulations, this is the end of the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
